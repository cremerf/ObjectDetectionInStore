{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step - Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The goal of this topic is to train the yolov5 model and obtain the weigths to detect objects in an image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - How to start training your object detection model?\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Download dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we are not going to download the dataset due to EC2 space limit.\n",
    "So we will map the dataset from the Eudes EC2 account.\n",
    "\n",
    "If you want to download it, you can use:\n",
    "```\n",
    "wget http://trax-geometry.s3.amazonaws.com/cvpr_challenge/SKU110K_fixed.tar.gz\n",
    "```\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) YoloV5 required structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 ) Image directories structure\n",
    "\n",
    "* Yolo V5 expects a folder architecture as following:\n",
    "\n",
    "        \n",
    "        data\n",
    "        ├── penguins\n",
    "        │   ├── images\n",
    "        │   │   ├── train\n",
    "        │   │   ├── validation\n",
    "        │   │   ├── test\n",
    "        │   ├── labels\n",
    "        │   │   ├── train\n",
    "        │   │   ├── validation\n",
    "        │   │   └── test\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You can get rid of \"penguins\" if you want)\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2) Labels structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* YOLO v5 expects annotations for each image in form of a .txt file which each line\n",
    "of the text file describes a bounding box."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This annotations must look like this:\n",
    "\n",
    "```\n",
    "0  0.480 0.631 0.692 0.713\n",
    "0  0.741 0.522 0.314 0.933\n",
    "27 0.785 0.506 0.390 0.151\n",
    "```\n",
    "\n",
    "The specification for each line is as follows.\n",
    "\n",
    "- One row per object.\n",
    "- Each row is: class | x_center | y_center | width | height |\n",
    "- Box coordinates must be normalized by the dimensions of the image (i.e. have values between 0 and 1).\n",
    "- Class numbers are zero-indexed (start from 0).\n",
    "\n",
    "The script in charge to create this structure is 'prepare_labels.py' and is located in 'model\\scripts\\packages\\prepare_labels.py'.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Data configuration files\n",
    "\n",
    "* The configs for the training task are divided into three YAML files, which are provided\n",
    "with the YoloV5 repo itself. We will customize these files depending on the task, to fit our \n",
    "desired needs.\n",
    "\n",
    "1. data-configurations file: describes datasets parameters\n",
    "    - train/val/test paths\n",
    "    - nc: number of classes\n",
    "    - names: classes names\n",
    "    \n",
    "2. hyperparameter config file: defines the hyperparameters for the training\n",
    "    - learning rate\n",
    "    - momemtum\n",
    "    - losses\n",
    "    - augmentation\n",
    "    - etc\n",
    "\n",
    "3. models-configuration file: dictates the model architecture.\n",
    "   These architectures are suitable for training with image size of 640*640 pixels\n",
    "    - YOLOv5n (nano)\n",
    "    - YOLOv5s (small)\n",
    "    - YOLOv5m (medium)\n",
    "    - YOLOv5l (large)\n",
    "    - YOLOv5x (extra large)\n",
    "\n",
    "Locations:\n",
    "\n",
    "```\n",
    "yolov5\n",
    "├── data\n",
    "|   ├── hyps                                # Hyper parameter configuration file\n",
    "|   |   ├── hyp.scratch-low.yaml\n",
    "|   |   ├── hyp.scratch-med.yaml\n",
    "|   |   ├── hyp.scratch-high.yaml\n",
    "├── models                                  # Model architecture file\n",
    "│   ├── yolov5l.yaml\n",
    "│   ├── yolov5m.yaml\n",
    "│   ├── yolov5n.yaml\n",
    "│   ├── yolov5s.yaml\n",
    "│   └── lyolov5x.yaml\n",
    "```\n",
    "\n",
    "```\n",
    "training\n",
    "├── analisis\n",
    "├── preparation\n",
    "├── yolo_config\n",
    "│   └── retail_config.yaml                  # Data configuration file\n",
    "```\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4)  Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this process, you'll need to build the preparation image. You need to run this line inside trainig folder.\n",
    "\n",
    "    - docker build -t training .\n",
    "\n",
    "Then, run the container:\n",
    "\n",
    "    - docker run --rm --net host --gpus all -it \\\n",
    "    -v /home/fabioalvarez/retail_prediction/training:/home/src/app \\\n",
    "    -v /home/eudesz/final_project/data:/home/src/dataset \\\n",
    "    -v /home/fabioalvarez/retail_prediction/data:/home/src/data \\\n",
    "    --workdir /home/src \\\n",
    "    training \\\n",
    "    bash\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As running this container, the trainning process will be started. If you don't understand the docker command, here it's a quickly example:\n",
    " \n",
    "    - docker run --rm --net host --gpus all -it \\ #\n",
    "    -v /home/fabioalvarez/retail_prediction/training:/home/src/app \\ #\n",
    "    -v /home/eudesz/final_project/data:/home/src/dataset \\ #\n",
    "    -v /home/fabioalvarez/retail_prediction/data:/home/src/data \\ #\n",
    "    --workdir /home/src \\ #\n",
    "    training \\ #\n",
    "    bash "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script that enables this structure is 'prepare_dataset.py' and is located in\n",
    "'model\\scripts\\packages\\prepare_dataset.py'.\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Transfer Learning\n",
    "\n",
    "Models are developed by two main parts: the backbone layers which serves as a feature extractor, \n",
    "and the head layers which computes the output predictions. To further compensate for a small\n",
    "dataset size, we’ll use the same backbone as the pretrained COCO model, and only train the\n",
    "model’s head. YOLOv5s6 backbone consists of 10 layers, who will be fixed by the ‘freeze’ \n",
    "argument.\n",
    "\n",
    "train script example:\n",
    "```\n",
    "python train.py --batch 32 --epochs 100 --data 'yolov5/data/retail_data.yaml'\n",
    "-- weights 'yolov5s.pt' --cache --freeze 10  --project retail_prediction --name 'feature_extraction'\n",
    "```\n",
    "\n",
    "- batch — batch size (-1 for auto batch size). Use the largest batch size that your hardware allows for.\n",
    "- epochs — number of epochs.\n",
    "- data — path to the data-configurations file.\n",
    "- weights — path to initial weights. COCO model will be downloaded automatically.\n",
    "- cache — cache images for faster training.\n",
    "- img — image size in pixels (default — 640).\n",
    "- freeze — number of layers to freeze\n",
    "- project— direction to save weights.\n",
    "- name — weigths folder name\n",
    "\n",
    "If ‘project’ and ‘name’ arguments are supplied, the results are automatically saved there.\n",
    "Else, they are saved to ‘runs/train’ directory. \n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Start trianing\n",
    "\n",
    "Run this inside yolov5 folder in the preparation container\n",
    "\n",
    "```\n",
    "python3 train.py --img 416 --batch 4 --epochs 3 \\\n",
    "    --data /home/src/app/yolo_config/retail_config.yaml \\\n",
    "    --weights yolov5s.pt --cache --project /home/src/data/weights \\\n",
    "    --name retail\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Step - Running Microservices\n",
    "\n",
    "This app is based in the \"new gen\" of microservices architecture:\n",
    "\n",
    "API: This microservice allows us to communicate with the frontend of the web page and is enable to receive the images, save them and also return and render the response (image of the shelves with). The Fast Api framework was used for this.\n",
    "\n",
    "Redis: This microservice is in charge of receiving the requirement from the client and queueing it, in order to send the requirements to the model as it delivers the result.\n",
    "\n",
    "Model: This microservice receives the jobs from Redis and passes them to a yolov5 model which is the one that will finally make the prediction. This result passes again through Redis and is rendered by means of the Fast Api microservice.\n",
    "\n",
    "Docker: For our system to work, a container is created for each microservice using Dockerfiles and Docker-compose. This also helps to secure our system when it is ready to go to production.\n",
    "\n",
    "\n",
    "### Up containers\n",
    "\n",
    "-  If you are using visual studio code, you can go to the most inferior side of the IDE and click the green buttom.\n",
    "1)  After that select \"open folder in container\".\n",
    "2)  Select the folder where the project is.\n",
    "3)  Select the option \"from docker compose\".\n",
    "4)  After that, attach to the api container"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf3fddaf5f16d859b6e8d0eeaf4cfc855ee191cae7b483f6b3cdefa4bf9da992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
