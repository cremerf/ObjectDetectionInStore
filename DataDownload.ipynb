{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKIA2JHUK4EGCLO2FNS4\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "load_dotenv()\n",
    "import os\n",
    "print(os.getenv(\"AWS_ACCESS_KEY_ID\"))\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3',aws_access_key_id=AWS_ACCESS_KEY_ID,aws_secret_access_key=AWS_SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = s3_resource.Bucket('anyoneai-datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'data_downloaded/annotations_'+subset+'.csv', names=[\"image_name\", \"x1\", \"y1\", \"x2\", \"y2\",\"class\", \"image_width\", \"image_height\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>class</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>208</td>\n",
       "      <td>537</td>\n",
       "      <td>422</td>\n",
       "      <td>814</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1268</td>\n",
       "      <td>1923</td>\n",
       "      <td>1365</td>\n",
       "      <td>2209</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1135</td>\n",
       "      <td>2074</td>\n",
       "      <td>1261</td>\n",
       "      <td>2166</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1045</td>\n",
       "      <td>2085</td>\n",
       "      <td>1122</td>\n",
       "      <td>2258</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>976</td>\n",
       "      <td>2036</td>\n",
       "      <td>1040</td>\n",
       "      <td>2177</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>863</td>\n",
       "      <td>2048</td>\n",
       "      <td>937</td>\n",
       "      <td>2194</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>772</td>\n",
       "      <td>2097</td>\n",
       "      <td>843</td>\n",
       "      <td>2244</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>659</td>\n",
       "      <td>2157</td>\n",
       "      <td>724</td>\n",
       "      <td>2222</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>568</td>\n",
       "      <td>2066</td>\n",
       "      <td>645</td>\n",
       "      <td>2198</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>488</td>\n",
       "      <td>2097</td>\n",
       "      <td>558</td>\n",
       "      <td>2257</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name    x1    y1    x2    y2   class  image_width  image_height\n",
       "0  train_0.jpg   208   537   422   814  object         3024          3024\n",
       "1  train_0.jpg  1268  1923  1365  2209  object         3024          3024\n",
       "2  train_0.jpg  1135  2074  1261  2166  object         3024          3024\n",
       "3  train_0.jpg  1045  2085  1122  2258  object         3024          3024\n",
       "4  train_0.jpg   976  2036  1040  2177  object         3024          3024\n",
       "5  train_0.jpg   863  2048   937  2194  object         3024          3024\n",
       "6  train_0.jpg   772  2097   843  2244  object         3024          3024\n",
       "7  train_0.jpg   659  2157   724  2222  object         3024          3024\n",
       "8  train_0.jpg   568  2066   645  2198  object         3024          3024\n",
       "9  train_0.jpg   488  2097   558  2257  object         3024          3024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "BUCKET_NAME = os.getenv('BUCKET_NAME')\n",
    "BUCKET_PREFIX = os.getenv('BUCKET_PREFIX')\n",
    "\n",
    "DATA_FOLDER = os.getenv('LOCATION_DIR') # data_downloaded\n",
    "OUTPUT_DATA_FOLDER = os.getenv('OUTPUT_DATA_FOLDER')\n",
    "OUTPUT_DATA_BB_FOLDER = os.getenv('OUTPUT_DATA_BB_FOLDER')\n",
    "\n",
    "LABELS_FOLDER = os.getenv('LABELS_FOLDER')\n",
    "IMAGES_FOLDER = os.getenv('IMAGES_FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data_v1/train/train_22.jpg')\n",
    "res = cv2.resize(img, dsize=(54, 140), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walkdir(DATA_FOLDER: str):\n",
    "    \"\"\"\n",
    "    Walk through all the files in a directory and its subfolders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    DATA_FOLDER : str\n",
    "        Path to the folder you want to walk.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        For each file found, yields a tuple having the path to the file\n",
    "        and the file name.\n",
    "    \"\"\"\n",
    "    for dirpath, _, files in os.walk(DATA_FOLDER):\n",
    "        for filename in files:\n",
    "            yield (dirpath, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = walkdir(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_filenames(directory: str, separator: str) -> list:\n",
    "    \"\"\"\n",
    "    This function will return all the filenames of the specified directory.\n",
    "\n",
    "    It uses os.walk to walkthrough over the entire directory and get only the files that end with .txt.\n",
    "        \n",
    "    Return\n",
    "    ------------------------------\n",
    "    list_of_filenames: list with filenames\n",
    "    \"\"\"\n",
    "    list_of_filenames = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith((\".png\", \".jpg\", \".jpeg\", \".gif\")):\n",
    "                list_of_filenames.append(os.path.join(root, file).split(separator)[-1])\n",
    "\n",
    "    return list_of_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.loc[data['image_name'] == 'train_0.jpg'].values:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_buffer = []\n",
    "starter = 0\n",
    "\n",
    "data = pd.read_csv(f'{DATA_FOLDER}/annotations_{subset}.csv', names=[\"image_name\", \"x1\", \"y1\", \"x2\", \"y2\",\"class\", \"image_width\", \"image_height\"])\n",
    "\n",
    "\n",
    "for i in data.loc[data['image_name'] == 'train_0.jpg'].values:\n",
    "    \n",
    "    b_center_x = (i[1] + i[3]) / 2 \n",
    "    b_center_y = (i[2] + i[4]) / 2\n",
    "    b_width    = (i[3] - i[1])\n",
    "    b_height   = (i[4] - i[2])\n",
    "\n",
    "    # Normalise the co-ordinates by the dimensions of the image\n",
    "    image_w = i[6]\n",
    "    image_h= i[7]\n",
    "    image_c = i[5]\n",
    "    b_center_x /= image_w \n",
    "    b_center_y /= image_h \n",
    "    b_width    /= image_w \n",
    "    b_height   /= image_h\n",
    "    \n",
    "    starter += 1\n",
    "\n",
    "    print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(starter, b_center_x, b_center_y, b_width, b_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in data.index:\n",
    "\n",
    "    # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
    "    b_center_x = (data.iloc[idx][\"x1\"] + data.iloc[idx][\"x2\"]) / 2 \n",
    "    b_center_y = (data.iloc[idx][\"y1\"] + data.iloc[idx][\"y2\"]) / 2\n",
    "    b_width    = (data.iloc[idx][\"x2\"] - data.iloc[idx][\"x1\"])\n",
    "    b_height   = (data.iloc[idx][\"y2\"] - data.iloc[idx][\"y1\"])\n",
    "\n",
    "    # Normalise the co-ordinates by the dimensions of the image\n",
    "    image_w = data.iloc[idx][\"image_width\"]\n",
    "    image_h= data.iloc[idx][\"image_height\"]\n",
    "    image_c = data.iloc[idx][\"class\"]\n",
    "    b_center_x /= image_w \n",
    "    b_center_y /= image_h \n",
    "    b_width    /= image_w \n",
    "    b_height   /= image_h \n",
    "\n",
    "    #Write the bbox details to the file \n",
    "    print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(idx, b_center_x, b_center_y, b_width, b_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_to_txt(DATA_FOLDER: str, OUTPUT_DATA_FOLDER: str, LABELS_FOLDER: str, subset: str):\n",
    "\n",
    "    # create path: data/labels\n",
    "    labels_folder_path = os.path.join(OUTPUT_DATA_FOLDER, LABELS_FOLDER)\n",
    "\n",
    "    if not os.path.exists(labels_folder_path):\n",
    "        os.makedirs(labels_folder_path)\n",
    "\n",
    "    # create path: data/labels/train\n",
    "    subset_labels_folder_path = os.path.join(labels_folder_path, subset)\n",
    "\n",
    "    if not os.path.exists(subset_labels_folder_path):\n",
    "        os.makedirs(subset_labels_folder_path)\n",
    "\n",
    "    data = pd.read_csv(f'{DATA_FOLDER}/annotations_{subset}.csv', names=[\"image_name\", \"x1\", \"y1\", \"x2\", \"y2\",\"class\", \"image_width\", \"image_height\" ])\n",
    "\n",
    "    print_buffer = []\n",
    "\n",
    "    # For each bounding box\n",
    "    for idx in data.index:\n",
    "\n",
    "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
    "        b_center_x = (data.iloc[idx][\"x1\"] + data.iloc[idx][\"x2\"]) / 2 \n",
    "        b_center_y = (data.iloc[idx][\"y1\"] + data.iloc[idx][\"y2\"]) / 2\n",
    "        b_width    = (data.iloc[idx][\"x2\"] - data.iloc[idx][\"x1\"])\n",
    "        b_height   = (data.iloc[idx][\"y2\"] - data.iloc[idx][\"y1\"])\n",
    "\n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w = data.iloc[idx][\"image_width\"]\n",
    "        image_h= data.iloc[idx][\"image_height\"]\n",
    "        image_c = data.iloc[idx][\"class\"]\n",
    "        b_center_x /= image_w \n",
    "        b_center_y /= image_h \n",
    "        b_width    /= image_w \n",
    "        b_height   /= image_h \n",
    "\n",
    "        #Write the bbox details to the file \n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(idx, b_center_x, b_center_y, b_width, b_height))\n",
    "\n",
    "        # Name of the file which we have to save \n",
    "        save_file_name = os.path.join(subset_labels_folder_path, data.iloc[idx][\"image_name\"].replace(\"jpg\", \"txt\"))\n",
    "        print(save_file_name)\n",
    "        # Save the annotation to disk\n",
    "        print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(f'{DATA_FOLDER}/annotations_{subset}.csv', names=[\"image_name\", \"x1\", \"y1\", \"x2\", \"y2\",\"class\", \"image_width\", \"image_height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>class</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>208</td>\n",
       "      <td>537</td>\n",
       "      <td>422</td>\n",
       "      <td>814</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1268</td>\n",
       "      <td>1923</td>\n",
       "      <td>1365</td>\n",
       "      <td>2209</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1135</td>\n",
       "      <td>2074</td>\n",
       "      <td>1261</td>\n",
       "      <td>2166</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1045</td>\n",
       "      <td>2085</td>\n",
       "      <td>1122</td>\n",
       "      <td>2258</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>976</td>\n",
       "      <td>2036</td>\n",
       "      <td>1040</td>\n",
       "      <td>2177</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208477</th>\n",
       "      <td>train_999.jpg</td>\n",
       "      <td>422</td>\n",
       "      <td>2386</td>\n",
       "      <td>675</td>\n",
       "      <td>2542</td>\n",
       "      <td>object</td>\n",
       "      <td>2336</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208478</th>\n",
       "      <td>train_999.jpg</td>\n",
       "      <td>427</td>\n",
       "      <td>2581</td>\n",
       "      <td>667</td>\n",
       "      <td>2715</td>\n",
       "      <td>object</td>\n",
       "      <td>2336</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208479</th>\n",
       "      <td>train_999.jpg</td>\n",
       "      <td>699</td>\n",
       "      <td>2365</td>\n",
       "      <td>823</td>\n",
       "      <td>2474</td>\n",
       "      <td>object</td>\n",
       "      <td>2336</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208480</th>\n",
       "      <td>train_999.jpg</td>\n",
       "      <td>1849</td>\n",
       "      <td>1678</td>\n",
       "      <td>2108</td>\n",
       "      <td>1769</td>\n",
       "      <td>object</td>\n",
       "      <td>2336</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208481</th>\n",
       "      <td>train_999.jpg</td>\n",
       "      <td>905</td>\n",
       "      <td>1589</td>\n",
       "      <td>1144</td>\n",
       "      <td>1712</td>\n",
       "      <td>object</td>\n",
       "      <td>2336</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1208482 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_name    x1    y1    x2    y2   class  image_width  \\\n",
       "0          train_0.jpg   208   537   422   814  object         3024   \n",
       "1          train_0.jpg  1268  1923  1365  2209  object         3024   \n",
       "2          train_0.jpg  1135  2074  1261  2166  object         3024   \n",
       "3          train_0.jpg  1045  2085  1122  2258  object         3024   \n",
       "4          train_0.jpg   976  2036  1040  2177  object         3024   \n",
       "...                ...   ...   ...   ...   ...     ...          ...   \n",
       "1208477  train_999.jpg   422  2386   675  2542  object         2336   \n",
       "1208478  train_999.jpg   427  2581   667  2715  object         2336   \n",
       "1208479  train_999.jpg   699  2365   823  2474  object         2336   \n",
       "1208480  train_999.jpg  1849  1678  2108  1769  object         2336   \n",
       "1208481  train_999.jpg   905  1589  1144  1712  object         2336   \n",
       "\n",
       "         image_height  \n",
       "0                3024  \n",
       "1                3024  \n",
       "2                3024  \n",
       "3                3024  \n",
       "4                3024  \n",
       "...               ...  \n",
       "1208477          4160  \n",
       "1208478          4160  \n",
       "1208479          4160  \n",
       "1208480          4160  \n",
       "1208481          4160  \n",
       "\n",
       "[1208482 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data_downloaded\"\n",
    "separator = '\\\\'\n",
    "filenames = get_list_filenames(directory=directory, separator=separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt_in_label_folder(subset_labels_folder_path, filename):\n",
    "       \n",
    "    print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(starter, b_center_x, b_center_y, b_width, b_height))\n",
    "    save_file_name = os.path.join(subset_labels_folder_path, filename)\n",
    "    # Save the annotation to disk\n",
    "\n",
    "    return print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_csv_to_txt(filename= 'train_0.jpg', subset_labels_folder_path=subset_labels_folder_path, df_annotations = df_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_multiprocessing_txt(filename: str):\n",
    "\n",
    "\n",
    "    return from_csv_to_txt(filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_multiprocessing_txt('train_0.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nestear la funcion en otra para que tome solo 1 parametro como iterador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Opcion 1: (falta de memoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = 'train'\n",
    "\n",
    "test1 = get_list_filenames(directory=directory, separator=separator)\n",
    "\n",
    "from_csv_to_txt_ = partial(from_csv_to_txt, subset_labels_folder_path, df_annotations)\n",
    "output = Parallel(n_jobs=num_cores, backend='threading', batch_size=\"auto\")(delayed(from_csv_to_txt_)(filename) for filename in test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKIA2JHUK4EGCLO2FNS4\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "load_dotenv()\n",
    "import os\n",
    "print(os.getenv(\"AWS_ACCESS_KEY_ID\"))\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "BUCKET_NAME = os.getenv('BUCKET_NAME')\n",
    "BUCKET_PREFIX = os.getenv('BUCKET_PREFIX')\n",
    "\n",
    "DATA_FOLDER = os.getenv('LOCATION_DIR') # data_downloaded\n",
    "OUTPUT_DATA_FOLDER = os.getenv('OUTPUT_DATA_FOLDER')\n",
    "OUTPUT_DATA_BB_FOLDER = os.getenv('OUTPUT_DATA_BB_FOLDER')\n",
    "\n",
    "LABELS_FOLDER = os.getenv('LABELS_FOLDER')\n",
    "IMAGES_FOLDER = os.getenv('IMAGES_FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_filenames(directory: str, separator: str) -> list:\n",
    "    \"\"\"\n",
    "    This function will return all the filenames of the specified directory.\n",
    "\n",
    "    It uses os.walk to walkthrough over the entire directory and get only the files that end with .txt.\n",
    "        \n",
    "    Return\n",
    "    ------------------------------\n",
    "    list_of_filenames: list with filenames\n",
    "    \"\"\"\n",
    "    list_of_filenames = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith((\".png\", \".jpg\", \".jpeg\", \".gif\")):\n",
    "                list_of_filenames.append(os.path.join(root, file).split(separator)[-1])\n",
    "\n",
    "    return list_of_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data_downloaded\"\n",
    "separator = '\\\\'\n",
    "filenames = get_list_filenames(directory=directory, separator=separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path: data/labels\n",
    "labels_folder_path = os.path.join(OUTPUT_DATA_FOLDER, LABELS_FOLDER)\n",
    "\n",
    "if not os.path.exists(labels_folder_path):\n",
    "    os.makedirs(labels_folder_path)\n",
    "\n",
    "# create path: data/labels/train\n",
    "subset_labels_folder_path = os.path.join(labels_folder_path, subset)\n",
    "\n",
    "if not os.path.exists(subset_labels_folder_path):\n",
    "    os.makedirs(subset_labels_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(f'{DATA_FOLDER}/annotations_{subset}.csv', names=[\"image_name\", \"x1\", \"y1\", \"x2\", \"y2\",\"class\", \"image_width\", \"image_height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_to_txt(filename: str, subset_labels_folder_path = subset_labels_folder_path, df_annotations: pd.DataFrame = df_annotations):\n",
    "\n",
    "    print_buffer = []\n",
    "    starter = 0\n",
    "\n",
    "    for i in df_annotations.loc[df_annotations['image_name'] == filename].values:\n",
    "        \n",
    "        b_center_x = (i[1] + i[3]) / 2 \n",
    "        b_center_y = (i[2] + i[4]) / 2\n",
    "        b_width    = (i[3] - i[1])\n",
    "        b_height   = (i[4] - i[2])\n",
    "\n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w = i[6]\n",
    "        image_h= i[7]\n",
    "        image_c = i[5]\n",
    "        b_center_x /= image_w \n",
    "        b_center_y /= image_h \n",
    "        b_width    /= image_w \n",
    "        b_height   /= image_h\n",
    "        \n",
    "        starter += 1\n",
    "    \n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(starter, b_center_x, b_center_y, b_width, b_height))\n",
    "    \n",
    "    \n",
    "    save_file_name = os.path.join(subset_labels_folder_path, filename).replace(\"jpg\", \"txt\")\n",
    "            # Save the annotation to disk\n",
    "\n",
    "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_multiprocessing_txt(filename: str):\n",
    "\n",
    "\n",
    "    return from_csv_to_txt(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probar solo con los filenames que tengan train como filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multiprocessing.Pool(num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Opcion 2: modificar funcion e iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.Pool state=RUN pool_size=12>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "p(func, iterable[, chunksize])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(num_cores) as p:\n",
    "    p.map(execute_multiprocessing_txt, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[39m=\u001b[39mnum_cores) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m----> 2\u001b[0m     executor\u001b[39m.\u001b[39;49mmap(from_csv_to_txt, filenames)\n",
      "File \u001b[1;32mc:\\Users\\Fede\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py:761\u001b[0m, in \u001b[0;36mProcessPoolExecutor.map\u001b[1;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    759\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mchunksize must be >= 1.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 761\u001b[0m results \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mmap(partial(_process_chunk, fn),\n\u001b[0;32m    762\u001b[0m                       _get_chunks(\u001b[39m*\u001b[39;49miterables, chunksize\u001b[39m=\u001b[39;49mchunksize),\n\u001b[0;32m    763\u001b[0m                       timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    764\u001b[0m \u001b[39mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "File \u001b[1;32mc:\\Users\\Fede\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:610\u001b[0m, in \u001b[0;36mExecutor.map\u001b[1;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     end_time \u001b[39m=\u001b[39m timeout \u001b[39m+\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 610\u001b[0m fs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubmit(fn, \u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39miterables)]\n\u001b[0;32m    612\u001b[0m \u001b[39m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[39m# before the first iterator value is required.\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult_iterator\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\Fede\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:610\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     end_time \u001b[39m=\u001b[39m timeout \u001b[39m+\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 610\u001b[0m fs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubmit(fn, \u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39miterables)]\n\u001b[0;32m    612\u001b[0m \u001b[39m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[39m# before the first iterator value is required.\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult_iterator\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\Fede\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py:715\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown_lock:\n\u001b[0;32m    714\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_broken:\n\u001b[1;32m--> 715\u001b[0m         \u001b[39mraise\u001b[39;00m BrokenProcessPool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_broken)\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown_thread:\n\u001b[0;32m    717\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcannot schedule new futures after shutdown\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "    executor.map(from_csv_to_txt, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    X_train_preprocessed = list(executor.map(from_csv_to_txt_, test1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf3fddaf5f16d859b6e8d0eeaf4cfc855ee191cae7b483f6b3cdefa4bf9da992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
